// pub struct OllamaProvider {
//     client: Client,
//     config: Config,
// }

// impl LlmProvider for OllamaProvider {
    
//     async fn request_chat_completion(&self, text: &str) -> eyre::Result<String> {
//         // OpenAI-specific implementation
//     }

//     async fn request_embedding(&self, text: &str) -> eyre::Result<Vec<f32>> {
//         // OpenAI-specific implementation
//     }
// }

// // Implement similar structs for Grok and Claude